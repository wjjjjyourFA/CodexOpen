---
layout: post
title: 聚类算法概述(k-Means++/FCM/凝聚层次聚类/DBSCAN)
comments: true
---

参考自[初识聚类算法:K均值、凝聚层次聚类和DBSCAN](http://blog.sina.com.cn/s/blog_62186b460101ard2.html)，[模糊聚类FCM算法](http://www.sjsjw.com/kf_other/article/030919ABA018874.asp)。

## 聚类的目的

将数据划分为若干个簇，簇内相似性大，簇间相似性小，聚类效果好。用于从数据中提取信息和规律。

## 聚类的概念

* **层次与划分**：当允许存在子簇时，将数据按照层次划分，最终得到的是一颗树。树中包含的层次关系即为聚类划分的层次关系。各个子簇不重叠，每个元素都隶属于某个level的子簇中。
* **互斥、重叠与模糊**：这个概念的核心在于，所有集合元素都不完全隶属于任何一个簇，而是按照一定隶属度归属于所有簇。对于任意一个元素，其隶属度和一般为1。
* **完全与部分**：完全聚类要求所有数据元素都必须有隶属，而部分聚类则允许噪音存在，不隶属于任何簇。

## 簇的分类

* **明显分离**：不同簇间任意元素距离都大于簇内元素距离。从图像上观察是明显分离类型的簇。
* **基于原型**：任意元素与它所隶属的簇的簇中心（簇内元素集合的质心）的距离大于到其他簇中心的距离。
* **基于图**：图中节点为对象，弧权值为距离。类似于明显分离的定义或基于原型的定义，只是用弧权值代替了人为规定的距离。
* **基于密度**：基于密度的簇分类是较为常用，也是应用范围最为广泛的一种分类方法。元素的稠密程度决定了簇的分布。当存在并希望分辨噪声时，或簇形状不规则时，往往采用基于密度的簇分类。

## 常用的聚类分析算法

* **基本k均值**：即k-means算法。簇的分类是基于原型的。用于已知簇个数的情况，且要求簇的形状基本满足圆形，不能区分噪声。
* 凝聚层次聚类：起初各个点为一个簇，而后按照距离最近凝聚，直到凝聚得到的簇个数满足用户要求。
* DBSCAN：基于密度和划分的聚类方法。

## 聚类算法的基本思想

### (1) 基本k均值聚类(hard c-means, HCM)
方法很简单，首先给出初始的几个簇中心。将所有元素按照到簇中心最近的归属原则，归属到各个簇。然后对各个簇求解新的簇中心（元素集合质心）。重复上述步骤直到质心不再明显变化后，即完成聚类。

采用何种距离可按照数据性质或项目要求。距离的分类可以参考[A-star算法概述及其在游戏开发中的应用分析](http://www.huhaoyu.com/A-star/)中提到的曼哈顿距离、对角线距离、欧几里得距离等。实际上相当于求解一个全局状态函数的最小值问题，状态函数是各个元素到最近簇中心的距离之和。

**该算法的特点有如下几点：**

* 其一，不一定得到全局最优解，当初始簇中心不满足要求时，可能只能得到局部最优解，当然有学者通过一定的预处理使得得到的初始簇中心满足一定条件，从而能够得到全局最优解，并将方法名改为**k-means++**。
* 其二，不能排除噪声点对聚类的影响。
* 其三，要求簇形状接近圆形。
* 要求完全聚类的情况。

![k-Means++](http://img.blog.csdn.net/20150619001412122)

**python代码**
**kMeansPlusPlus.py**

此代码使用的是k-means++算法，采用约定的方法使得到的初始聚类中心能够在后面的迭代过程中收敛到最优解。

### (2)Extra 基于模糊数学的c均值聚类(FCM)
模糊c均值聚类(fuzzy c-means clustering)与硬划分k均值聚类相同，都是一种**基于划分的**聚类分析方法，但FCM是HCM的自然进阶版。与k均值聚类不同的是，模糊c均值聚类的点按照不同的**隶属度ui**隶属于不同的**聚类中心vi**，聚类的过程类似k均值聚类。(详见：[模糊聚类FCM算法](http://www.sjsjw.com/kf_other/article/030919ABA018874.asp))

**聚类步骤：**

* 初始化。采用k-means++的方法确定初始聚类中心，确保最优解。
* 确定各个点对各个聚类中心的**隶属度u(i,j)**。**m为加权指数**。公式如下：
* `u(i,j) = (sum(distance(point(j), center(i)) / distance(point(j), center(k)))^(1/(m-1)))^-1`
* 确定新的聚类中心，标记聚类中心变化轨迹。公式如下：
* `v(i) = sum(u(i,j)^m * point(j)) / sum(u(i,j)^m)`
* 判断聚类中心变化幅值是否小于给定的误差限。如不满足返回步骤2，否则退出循环。
* 打印聚类中心轨迹和聚类结果。

![FCM](http://img.blog.csdn.net/20150619001547306)

**python代码**
**fuzzyCMeansClustering.py**

**该算法的特点有如下几点：**

* 主要特点与普通的k均值聚类类似。
* 要求完全聚类，不能区分噪声点。
* 聚类的中心符合度更高，但计算效率相对较低。
* 采用了**平滑参数**和**隶属度**的概念，使得各点的并不直接隶属于单个聚类中心。

### (3) 凝聚层次聚类

初始状态各个元素各自为簇，每次合并簇间距离最小的簇。直到簇个数满足要求或合并超过90%。类似**huffman树算法和查并集。**上述距离的定义也有几种分类：包括簇间元素的最小距离，簇间元素的最大距离，和簇质心距离。

**该算法的特点有如下几点：**

* 凝聚聚类耗费的存储空间相对于其他几种方法要高。
* 可排除噪声点的干扰，但有可能噪声点分为一簇。
* 适合形状不规则，不要求聚类完全的情况。
* 合并操作不能撤销。
* 应注意，合并操作必须有一个合并限制比例，否则可能发生过度合并导致所有分类中心聚集，造成聚类失败。

![凝聚层次聚类](http://img.blog.csdn.net/20150619001618804)

**python代码**
**agglomerativeHierarchical.py**


### (4) DBSCAN
DBSCAN是一种基于密度的聚类算法。因此首先应定义密度的概念。
密度是以一个点为中心2*eps边长的正方形区域内点的个数。
并将不同密度的点划归为不同类型的点：

* 当密度大于阈值MinPs时，称为核心点。
	数据点的邻域内至少有 `minPts` 个点（包括该点自身）
	
* 当密度小于阈值MinPs，但领域内核心点的数量大于等于1，称为边界点。
	本身不是核心点，但落在某个核心点的邻域内
	
* 非核心点且非边界点，称为噪声点。

**算法参数**
  1. `eps` (邻域半径): 用于定义一个点的邻域范围。
  2. `minPts`: 在 `eps` 范围内的最小点数（包括该点），用于判定核心点。

**具体操作：**

* 将所有邻近的核心点划分到同一个簇中。
* 将所有边界点划分到其领域内的核心点的簇中。
* 噪声点不做归属处理。

**该算法的特点有如下几点：**

* 可排除噪声点的干扰。
* 适合形状不规则，不要求聚类完全的情况。
* 合并操作不能撤销。
* `minPointsNumberWithinBoundary`和`eps`决定了聚类的粒度和范围，当`eps`增大或`minPointsNumberWithinBoundary`减小时，都会使聚类的粒度更粗，形成范围更大的簇。对于特定的问题，需要调整**`eps`**和**`minPointsNumberWithinBoundary`**以满足聚类的要求。
* 基于密度的聚类一定程度上回避了距离的计算，可以提高效率。

![DBSCAN](http://img.blog.csdn.net/20150619001645544)

**python代码**

**dbscan.py**

## 后记

在学习和分析过程中发现几点待解决的问题：

* 其一，上述聚类过程都需要**人为指定聚类中心数目**，然而聚类的过程如果需人为干预，这可能是一个比较麻烦的问题。解决办法可以是采用多个候选聚类中心数目`{i,i+1,...k}`，对于不同的聚类中心数目都会有对应的分析结果，再采用**贝叶斯定理**。另一方面，机器无法知道人所需要的聚类粒度和聚类数目，如果完全由机器确定，也是不合理的。
* 其二，k-means聚类必须是**完全聚类**，对距离的选择也可以依据问题而定。
* 其三，实际上凝聚层次聚类和基于密度的DBSCAN聚类都有一个**合并的过程**，对于这种合并最好的算法应该是**查并集**，其时间复杂度为**`O(n * f(n))`**，对于目前常见的大整数n，**`f(n) < 4`**。但如果过于追求效率，那么就违背了python语言开发和分析数据的优势。
* 其四，凝聚层次聚类和基于密度的DBSCAN聚类都对**合并的程度**有一定要求。凝聚层次聚类通过**`mergeRatio`**来确定合并的比例；而DBSCAN是通过**`eps`**和**`minPointsNumber`**来确定聚类的粒度。

## Stargazers over time

[![Stargazers over time](https://starchart.cc/HaoyuHu/clusterAnalysis.svg)](https://starchart.cc/HaoyuHu/clusterAnalysis)

